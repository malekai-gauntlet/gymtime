# Voice Logging Feature Implementation Plan

## Overview
Implement voice-based workout logging directly in the HomeView, allowing users to record their workouts through natural speech with a responsive UI and immediate transcription.

## Technical Components
1. **Audio Recording** âœ…
   - ~~Implement audio recording using AVFoundation~~ âœ…
   - ~~Add necessary microphone permissions~~ âœ…
   - ~~Create audio session management~~ âœ…
   - ~~Implement audio level monitoring for waveform visualization~~ âœ…

2. **Speech Recognition** âœ…
   - ~~Integrate Apple's Speech Recognition framework~~ âœ…
   - ~~Add required permissions~~ âœ…
   - ~~Implement real-time transcription~~ âœ…
   - ~~Handle continuous recognition mode~~ âœ…

3. **UI Components** âœ…
   - ~~Add recording button to HomeView with animation states:~~ âœ…
     - ~~Idle state (microphone icon)~~ âœ…
     - ~~Recording state (pulsing animation)~~ âœ…
     - ~~Processing state (loading spinner)~~ âœ…
   - ~~Implement screen dimming overlay with tap-to-stop~~ âœ…
   - ~~Create animated waveform visualization using audio levels~~ âœ…
   - ~~Add live transcription display~~ âœ…
   - ~~Add processing indicator~~ âœ…
   - ~~Implement haptic feedback for state changes~~ âœ…

4. **Data Processing** ğŸ”„
   - ~~Parse transcribed text into workout data using OpenAI~~ âœ…
   - ~~Extract structured fields:~~ âœ…
     - ~~Exercise name~~ âœ…
     - ~~Weight~~ âœ…
     - ~~Sets~~ âœ…
     - ~~Reps~~ âœ…
     - ~~Notes~~ âœ…
   - ~~Handle natural language variations~~ âœ…
   - ~~Format data for storage~~ âœ…
   - ~~Implement data cleaning helpers:~~ âœ…
     - ~~Capitalize exercise names~~ âœ…
     - ~~Convert word numbers to digits~~ âœ…
     - ~~Handle units consistently~~ âœ…
   - Enhance parsing for:
     - Time-based workouts
     - Multiple exercises
     - EMOM/circuit workouts
     - Supersets
     - Rehab/mobility work

5. **State Management** âœ…
   - ~~Track recording states:~~ âœ…
     - ~~Idle~~ âœ…
     - ~~Recording~~ âœ…
     - ~~Processing~~ âœ…
     - ~~Error~~ âœ…
   - ~~Manage audio session state~~ âœ…
   - ~~Handle transcription state~~ âœ…
   - ~~Update workout list~~ âœ…
   - Handle background/foreground transitions

## Implementation Steps

### Phase 1: Setup & Permissions âœ…
1. ~~Add required permission keys to Info.plist:~~ âœ…
   - ~~`NSMicrophoneUsageDescription`~~ âœ…
   - ~~`NSSpeechRecognitionUsageDescription`~~ âœ…
2. ~~Create AudioManager for handling recording and audio levels~~ âœ…
3. ~~Create SpeechRecognitionManager~~ âœ…
4. Set up OpenAI integration for parsing â³

### Phase 2: Core Recording Functionality âœ…
1. ~~Implement basic audio recording with level monitoring~~ âœ…
2. ~~Add speech recognition with continuous mode~~ âœ…
3. ~~Create recording state management~~ âœ…
4. ~~Add basic UI indicators~~ âœ…
5. Implement OpenAI parsing integration â³

### Phase 3: UI Enhancement ğŸ”„
1. ~~Implement screen dimming overlay with tap-to-stop~~ âœ…
2. ~~Create waveform visualization using audio levels~~ âœ…
3. ~~Add recording button animations:~~ âœ…
   - ~~Idle microphone icon~~ âœ…
   - ~~Recording pulse effect~~ âœ…
   - Processing spinner
4. ~~Add live transcription display~~ âœ…
5. ~~Implement haptic feedback~~ âœ…
6. Add loading states and error handling UI

### Phase 4: Data Processing
1. Create workout text parser using OpenAI
2. Implement data cleaning helpers:
   - Word to number conversion
   - Text capitalization
   - Unit standardization
3. Add workout entry creation
4. Update workout table
5. Implement error handling and retries

### Phase 5: Polish & Testing
1. Add error handling with user feedback
2. Implement fallback mechanisms
3. Add loading states
4. Polish animations and transitions
5. Add user feedback:
   - Success toasts
   - Error messages
   - Processing indicators
6. Implement background mode handling
7. Add accessibility support

## Required Permissions âœ…
```xml
<!-- Info.plist entries -->
<key>NSMicrophoneUsageDescription</key>
<string>We need access to your microphone to record your workout descriptions.</string>
<key>NSSpeechRecognitionUsageDescription</key>
<string>We need speech recognition to convert your voice into workout entries.</string>
```

## Dependencies
- ~~AVFoundation~~ âœ…
- Speech â³
- ~~SwiftUI~~ âœ…
- ~~Combine~~ âœ…
- OpenAI API (for natural language parsing)

## Data Model
```swift
struct WorkoutEntry {
    let id: UUID
    let date: Date
    var exercise: String
    var weight: String?
    var sets: Int?
    var reps: Int?
    var notes: String?
}
```

## Notes
- ~~Ensure smooth transition between states with proper cleanup~~ âœ…
- Provide clear visual and haptic feedback for all user actions
- Handle background/foreground transitions gracefully
- Consider accessibility implications
- Plan for error cases and network issues
- ~~Implement proper cleanup of audio session~~ âœ…
- Add retry mechanism for failed API calls
- Consider offline support for basic recording
- Implement proper error messages for each failure case
- Add data validation before storage

## Next Steps (Priority Order):
1. Enhance workout parsing for different workout styles:
   - Time-based workouts (e.g., "10 minutes of abs")
   - Multiple exercises in one recording
   - EMOM-style workouts
   - Circuit-style workouts
   - Supersets
   - Rehab/mobility work

2. Add data persistence:
   - Implement local storage for workouts
   - Add data migration support
   - Handle offline capabilities

3. Polish and Testing:
   - Add comprehensive error handling
   - Implement retry mechanisms for failed API calls
   - Add loading states and transitions
   - Improve accessibility support
   - Add unit tests for parsing logic

Would you like to start with enhancing the workout parsing or move on to data persistence? 